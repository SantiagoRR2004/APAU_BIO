# -*- coding: utf-8 -*-
"""APAU_BIO_practica11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vt2YkgZhuy4yPg1JvnEHHnLKHnhLf7KK
"""

# prerequisites
import torch
import torch.nn as nn
import torchvision.transforms.functional as t_F
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable
from torchvision.utils import save_image
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from torchvision.utils import make_grid
import matplotlib.patches as mpatches

from torchsummary import summary

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class Generator(nn.Module):

    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):
        super(Generator, self).__init__()

        self.z_dim = z_dim

        self.gen = nn.Sequential(
            self.get_generator_block(z_dim, hidden_dim * 4, kernel_size=3, stride=2),
            self.get_generator_block(
                hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1
            ),
            self.get_generator_block(
                hidden_dim * 2,
                hidden_dim,
                kernel_size=3,
                stride=2,
            ),
            self.get_generator_final_block(
                hidden_dim, im_chan, kernel_size=4, stride=2
            ),
        )

    def get_generator_block(
        self, input_channel, output_channel, kernel_size, stride=1, padding=0
    ):
        return nn.Sequential(
            nn.ConvTranspose2d(
                input_channel, output_channel, kernel_size, stride, padding
            ),
            nn.BatchNorm2d(output_channel),
            nn.ReLU(inplace=True),
        )

    def get_generator_final_block(
        self, input_channel, output_channel, kernel_size, stride=1, padding=0
    ):
        return nn.Sequential(
            nn.ConvTranspose2d(
                input_channel, output_channel, kernel_size, stride, padding
            ),
            nn.Tanh(),
        )

    def forward(self, noise):
        x = noise.view(len(noise), self.z_dim, 1, 1)
        return self.gen(x)


summary(Generator(100).to(device), (100,))
print(Generator(100))


class Generator(nn.Module):
    def __init__(self, g_input_dim=100, g_output_dim=784):
        super(Generator, self).__init__()
        self.fc1 = nn.Linear(g_input_dim, 256)
        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features * 2)
        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features * 2)
        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)

    # forward method
    def forward(self, x):
        x = F.leaky_relu(self.fc1(x), 0.2)
        x = F.leaky_relu(self.fc2(x), 0.2)
        x = F.leaky_relu(self.fc3(x), 0.2)
        return torch.tanh(self.fc4(x))


summary(Generator(100).to(device), (100,))
print(Generator(100))


class Discriminator(nn.Module):

    def __init__(self, im_chan=1, hidden_dim=16):
        super(Discriminator, self).__init__()
        self.disc = nn.Sequential(
            self.get_critic_block(im_chan, hidden_dim * 4, kernel_size=4, stride=2),
            self.get_critic_block(
                hidden_dim * 4,
                hidden_dim * 8,
                kernel_size=4,
                stride=2,
            ),
            self.get_critic_final_block(
                hidden_dim * 8,
                1,
                kernel_size=4,
                stride=2,
            ),
        )

    def get_critic_block(
        self, input_channel, output_channel, kernel_size, stride=1, padding=0
    ):
        return nn.Sequential(
            nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),
            nn.BatchNorm2d(output_channel),
            nn.LeakyReLU(0.2, inplace=True),
        )

    def get_critic_final_block(
        self, input_channel, output_channel, kernel_size, stride=1, padding=0
    ):
        return nn.Sequential(
            nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),
        )

    def forward(self, image):
        return self.disc(image)


summary(Discriminator().to(device), (1, 28, 28))
print(Discriminator())


class Discriminator(nn.Module):
    def __init__(self, d_input_dim=784):
        super(Discriminator, self).__init__()
        self.fc1 = nn.Linear(d_input_dim, 1024)
        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features // 2)
        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features // 2)
        self.fc4 = nn.Linear(self.fc3.out_features, 1)

    # forward method
    def forward(self, x):
        x = F.leaky_relu(self.fc1(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc2(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc3(x), 0.2)
        x = F.dropout(x, 0.3)
        return torch.sigmoid(self.fc4(x))


summary(Discriminator().to(device), (784,))
print(Discriminator())


class Classifier(nn.Module):
    num_classes = 10
    img_dim = 28
    num_epochs = 50
    batch_size = 128
    nChannels = 1

    def __init__(self):
        super(Classifier, self).__init__()
        if torch.cuda.is_available():
            self.device = torch.device("cuda:0")
        else:
            self.device = torch.device("cpu")

        self.net = self.getCNN()

    def forward(self, image):
        return self.net(image)

    def getCNN(self) -> torch.nn.Sequential:
        net = torch.nn.Sequential(
            torch.nn.Conv2d(1, 32, kernel_size=3),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2),
            torch.nn.Conv2d(32, 64, kernel_size=3),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2),
            torch.nn.Conv2d(64, 128, kernel_size=3),
            torch.nn.ReLU(),
            torch.nn.Flatten(),
            torch.nn.Linear(1152, 10),
            torch.nn.Softmax(dim=1),
        ).to(self.device)

        return net

    def train(self, train_loader):

        # loss_fn = torch.nn.CrossEntropyLoss()
        optimizer = torch.optim.RMSprop(self.net.parameters(), lr=0.001)
        criterion = torch.nn.CrossEntropyLoss()

        loss_v = np.empty(0)
        accuracy_v = np.empty(0)

        for epoch in range(self.num_epochs):
            self.net.train()
            train_loss = 0.0
            correct_predictions = 0
            total_samples = 0
            for i, data in enumerate(train_loader, 0):

                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data

                inputs = inputs.to(self.device)
                labels = labels.to(self.device)

                # forward + backward + optimize
                optimizer.zero_grad()
                outputs = self.net(inputs)
                batch_loss = criterion(outputs, labels)
                batch_loss.backward()
                optimizer.step()

                # # print statistics
                train_loss += batch_loss.item()
                _, predicted = torch.max(outputs, 1)
                correct_predictions += (predicted == labels).sum().item()
                total_samples += labels.size(0)

            accuracy = correct_predictions / total_samples

            print(
                "Epoch {:02d}: loss {:.4f} - accuracy {:.4f} ".format(
                    epoch + 1, train_loss, accuracy
                )
            )

            loss_v = np.append(loss_v, train_loss)
            accuracy_v = np.append(accuracy_v, accuracy)

    def save_model(self, name: str = "Classifier.pth"):
        torch.save(self.net.state_dict(), name)

    def plot_image(self, image: torch.Tensor):
        # Convert the tensor to a numpy array
        image = image.cpu().numpy()
        # Transpose the dimensions to (height, width, channels)
        image = np.transpose(image, (1, 2, 0))
        plt.imshow(image, cmap="gray" if self.nChannels == 1 else None)

    def load_model(self, path: str = "Classifier.pth"):
        self.net.load_state_dict(torch.load(path, map_location=self.device))
        self.net.eval()

    def test(self, test_loader):

        correct_predictions_val = 0
        total_samples_val = 0
        inputs_val = []
        labels_val = []
        outputs_val = []
        predicted_val = []

        with torch.no_grad():
            for data in test_loader:
                inputs, labels = data
                inputs_val.append(inputs)
                inputs = inputs.to(self.device)
                labels_val.append(labels)
                labels = labels.to(self.device)
                outputs = self.net(inputs)
                outputs_val.append(outputs)
                _, predicted = torch.max(outputs, 1)
                predicted_val.append(predicted)
                correct_predictions_val += (predicted == labels).sum().item()
                total_samples_val += labels.size(0)

        inputs_val = torch.cat(inputs_val, dim=0)
        labels_val = torch.cat(labels_val, dim=0)
        outputs_val = torch.cat(outputs_val, dim=0)
        predicted_val = torch.cat(predicted_val, dim=0)

        accuracy_val = correct_predictions_val / total_samples_val
        print("Test accuracy: {:.4f}".format(accuracy_val))

        # Set up the plot
        plt.ion()  # Turn on interactive mode
        fig, ax = plt.subplots()

        # Loop through all images and show one every 10 seconds
        for i in range(len(inputs_val)):
            ax.clear()  # Clear previous plot
            self.plot_image(inputs_val[i])  # Pass ax to your plot_image function
            predicted_class = self.class_names[predicted_val[i].item()]
            actual_class = self.class_names[labels_val[i].item()]
            ax.set_title(f"Predicted: {predicted_class}, Actual: {actual_class}")

            probs = F.softmax(outputs_val[i], dim=0)

            # Update the class percentages dynamically
            class_percentages = {
                self.class_names[j]: probs[j].item() * 100
                for j in range(len(self.class_names))
            }

            # Update legend lines with new percentages
            legend_lines = [
                f"{class_name}: {percentage:.1f}%"
                for class_name, percentage in class_percentages.items()
            ]

            legend_patches = [
                mpatches.Patch(color="none", label=line) for line in legend_lines
            ]

            ax.legend(
                handles=legend_patches,
                loc="center left",
                bbox_to_anchor=(1.05, 0.5),
                handlelength=0,
                handletextpad=0,
            )

            plt.tight_layout()
            plt.draw()  # Update the figure
            plt.pause(5)  # Pause for 5 seconds to show the image

        plt.ioff()  # Turn off interactive mode
        plt.show()


summary(Classifier().to(device), (1, 28, 28))
print(Classifier())

transform = transforms.Compose(
    [
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,)),  # Normalizes to [-1, 1]
    ]
)

train_data = datasets.FashionMNIST(
    root="./data", train=True, download=True, transform=transform
)

test_data = datasets.FashionMNIST(
    root="./data", train=False, download=True, transform=transform
)

print(train_data)
print(train_data.data.size())

batch_size = 128

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)

dataiter = iter(train_loader)
images, labels = next(dataiter)
plt.figure(figsize=(4, 4))
plt.axis("off")
plt.title("Training Images")
inverted_images = t_F.invert(images[0:48])
plt.imshow(
    np.transpose(
        make_grid(inverted_images.to(device), padding=2, normalize=True).cpu(),
        (1, 2, 0),
    )
)

print("Shape of loading one batch:", images.shape)
print("Total no. of batches present in trainloader:", len(train_loader))

G = Generator().to(device)
D = Discriminator().to(device)
fashion_dim = train_data.data.size(1) * train_data.data.size(2)
z_dim = 100
print(fashion_dim)

# loss
criterion = nn.BCELoss()

# optimizer
lr = 0.0002
G_optimizer = optim.Adam(G.parameters(), lr=lr)
D_optimizer = optim.Adam(D.parameters(), lr=lr)


def G_train(x):
    # =======================Train the generator=======================#
    G.zero_grad()

    z = Variable(torch.randn(batch_size, z_dim).to(device))
    y = Variable(torch.ones(batch_size, 1).to(device))

    G_output = G(z)
    D_output = D(G_output)
    G_loss = criterion(D_output, y)

    # gradient backprop & optimize ONLY G's parameters
    G_loss.backward()
    G_optimizer.step()

    return G_loss.data.item()


def D_train(x):
    # =======================Train the discriminator=======================#
    D.zero_grad()

    # train discriminator on real
    x_real, y_real = x.view(-1, fashion_dim).to(device), torch.ones(x.size(0), 1).to(
        device
    )
    x_real, y_real = Variable(x_real), Variable(y_real)

    D_output = D(x_real)
    D_real_loss = criterion(D_output, y_real)
    D_real_score = D_output

    # train discriminator on fake
    z = Variable(torch.randn(x.size(0), z_dim).to(device))
    x_fake, y_fake = G(z), Variable(torch.zeros(x.size(0), 1).to(device))

    D_output = D(x_fake)
    D_fake_loss = criterion(D_output, y_fake)
    D_fake_score = D_output

    # gradient backprop & optimize ONLY D's parameters
    D_loss = D_real_loss + D_fake_loss
    D_loss.backward()
    D_optimizer.step()

    return D_loss.data.item()


import os

os.makedirs("samples", exist_ok=True)


# Function to plot losses
def plot_losses(d_losses, g_losses):
    plt.figure(figsize=(10, 5))
    plt.plot(d_losses, label="Discriminative loss")
    plt.plot(g_losses, label="Generative loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.suptitle("Loss over Epochs")
    plt.savefig("samples/losses.png")


def plot_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1)):
    noise = torch.randn(examples, z_dim, device=device)
    generated_images = G(noise)
    generated_images = generated_images.reshape(examples, 28, 28)

    plt.figure(figsize=figsize)
    for i in range(examples):
        plt.subplot(dim[0], dim[1], i + 1)
        plt.imshow(
            generated_images[i].cpu().detach().numpy(),
            interpolation="nearest",
            cmap="gray_r",
        )
        plt.axis("off")
    plt.tight_layout()


n_epoch = 200
sample_interval = 10
D_losses, G_losses = [], []
for epoch in range(1, n_epoch + 1):
    D_loss_epoch = 0.0
    G_loss_epoch = 0.0
    for batch_idx, (x, _) in enumerate(train_loader):
        D_loss_epoch += D_train(x)
        G_loss_epoch += G_train(x)
    D_loss_epoch /= batch_idx + 1
    G_loss_epoch /= batch_idx + 1
    D_losses.append(D_loss_epoch)
    G_losses.append(G_loss_epoch)

    print(
        "[%d/%d]: loss_d: %.3f, loss_g: %.3f"
        % (
            (epoch),
            n_epoch,
            torch.mean(torch.FloatTensor(D_losses)),
            torch.mean(torch.FloatTensor(G_losses)),
        )
    )
    if epoch % sample_interval == 0 or epoch == n_epoch:
        plot_images(epoch, G)

plot_losses(D_losses, G_losses)

# Save the model
torch.save(G.state_dict(), "G.pth")
torch.save(D.state_dict(), "D.pth")

# Load the model
G.load_state_dict(torch.load("G.pth"))
D.load_state_dict(torch.load("D.pth"))

plt.show()
