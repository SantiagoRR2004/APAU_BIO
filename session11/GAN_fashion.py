# -*- coding: utf-8 -*-
"""APAU_BIO_practica11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vt2YkgZhuy4yPg1JvnEHHnLKHnhLf7KK
"""

# prerequisites
import torch
import torch.nn as nn
import torchvision.transforms.functional as t_F
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable
from torchvision.utils import save_image
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from torchvision.utils import make_grid
import matplotlib.patches as mpatches
from torchsummary import summary
from generatorSimple import Generator

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class Discriminator(nn.Module):
    def __init__(self, d_input_dim=784):
        super(Discriminator, self).__init__()
        self.fc1 = nn.Linear(d_input_dim, 1024)
        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features // 2)
        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features // 2)
        self.fc4 = nn.Linear(self.fc3.out_features, 1)

    # forward method
    def forward(self, x):
        x = F.leaky_relu(self.fc1(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc2(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc3(x), 0.2)
        x = F.dropout(x, 0.3)
        return torch.sigmoid(self.fc4(x))


summary(Discriminator().to(device), (784,))
print(Discriminator())


class Classifier(nn.Module):
    num_classes = 10
    img_dim = 28
    num_epochs = 50
    batch_size = 128
    nChannels = 1

    def __init__(self):
        super(Classifier, self).__init__()
        if torch.cuda.is_available():
            self.device = torch.device("cuda:0")
        else:
            self.device = torch.device("cpu")

        self.net = self.getCNN()

        self.class_names = []

    def forward(self, image):
        return self.net(image)

    def getCNN(self) -> torch.nn.Sequential:
        net = torch.nn.Sequential(
            torch.nn.Conv2d(1, 32, kernel_size=3),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2),
            torch.nn.Conv2d(32, 64, kernel_size=3),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2),
            torch.nn.Conv2d(64, 128, kernel_size=3),
            torch.nn.ReLU(),
            torch.nn.Flatten(),
            torch.nn.Linear(1152, 10),
            torch.nn.Softmax(dim=1),
        ).to(self.device)

        return net

    def train(self, train_loader):

        # loss_fn = torch.nn.CrossEntropyLoss()
        optimizer = torch.optim.RMSprop(self.net.parameters(), lr=0.001)
        criterion = torch.nn.CrossEntropyLoss()

        loss_v = np.empty(0)
        accuracy_v = np.empty(0)

        for epoch in range(self.num_epochs):
            self.net.train()
            train_loss = 0.0
            correct_predictions = 0
            total_samples = 0
            for i, data in enumerate(train_loader, 0):

                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data

                inputs = inputs.to(self.device)
                labels = labels.to(self.device)

                # forward + backward + optimize
                optimizer.zero_grad()
                outputs = self.net(inputs)
                batch_loss = criterion(outputs, labels)
                batch_loss.backward()
                optimizer.step()

                # # print statistics
                train_loss += batch_loss.item()
                _, predicted = torch.max(outputs, 1)
                correct_predictions += (predicted == labels).sum().item()
                total_samples += labels.size(0)

            accuracy = correct_predictions / total_samples

            print(
                "Epoch {:02d}: loss {:.4f} - accuracy {:.4f} ".format(
                    epoch + 1, train_loss, accuracy
                )
            )

            loss_v = np.append(loss_v, train_loss)
            accuracy_v = np.append(accuracy_v, accuracy)

    def save_model(self, name: str = "Classifier.pth"):
        torch.save(self.net.state_dict(), name)

    def plot_image(self, image: torch.Tensor):
        # Convert the tensor to a numpy array
        image = image.cpu().numpy()
        # Transpose the dimensions to (height, width, channels)
        image = np.transpose(image, (1, 2, 0))
        plt.imshow(image, cmap="gray" if self.nChannels == 1 else None)

    def load_model(self, path: str = "Classifier.pth"):
        self.net.load_state_dict(torch.load(path, map_location=self.device))
        self.net.eval()

    def predict(self, test_loader):

        total_samples_val = 0
        inputs_val = []
        labels_val = []
        outputs_val = []
        predicted_val = []

        with torch.no_grad():
            for data in test_loader:
                inputs, labels = data
                inputs_val.append(inputs)
                inputs = inputs.to(self.device)
                labels_val.append(labels)
                labels = labels.to(self.device)
                outputs = self.net(inputs)
                outputs_val.append(outputs)
                _, predicted = torch.max(outputs, 1)
                predicted_val.append(predicted)
                total_samples_val += labels.size(0)

        inputs_val = torch.cat(inputs_val, dim=0)
        labels_val = torch.cat(labels_val, dim=0)
        outputs_val = torch.cat(outputs_val, dim=0)
        predicted_val = torch.cat(predicted_val, dim=0)

        # Set up the plot
        plt.ion()  # Turn on interactive mode
        fig, ax = plt.subplots()

        # Loop through all images and show one every 10 seconds
        for i in range(len(inputs_val)):
            ax.clear()  # Clear previous plot
            self.plot_image(inputs_val[i])  # Pass ax to your plot_image function
            predicted_class = self.class_names[predicted_val[i].item()]
            ax.set_title(f"Predicted: {predicted_class}")

            probs = F.softmax(outputs_val[i], dim=0)

            # Update the class percentages dynamically
            class_percentages = {
                self.class_names[j]: probs[j].item() * 100
                for j in range(len(self.class_names))
            }

            # Update legend lines with new percentages
            legend_lines = [
                f"{class_name}: {percentage:.1f}%"
                for class_name, percentage in class_percentages.items()
            ]

            legend_patches = [
                mpatches.Patch(color="none", label=line) for line in legend_lines
            ]

            ax.legend(
                handles=legend_patches,
                loc="center left",
                bbox_to_anchor=(1.05, 0.5),
                handlelength=0,
                handletextpad=0,
            )

            plt.tight_layout()
            plt.draw()  # Update the figure
            plt.pause(5)  # Pause for 5 seconds to show the image

        plt.ioff()  # Turn off interactive mode
        plt.show()


summary(Classifier().to(device), (1, 28, 28))
print(Classifier())


class GeneratedDataset(Dataset):
    def __init__(self, images):
        self.images = images
        self.labels = torch.zeros(
            images.size(0), dtype=torch.long
        )  # Etiquetas dummy para las im√°genes generadas

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        return self.images[idx], self.labels[idx]


if __name__ == "__main__":
    transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,)),  # Normalizes to [-1, 1]
        ]
    )

    train_data = datasets.FashionMNIST(
        root="./data", train=True, download=True, transform=transform
    )

    test_data = datasets.FashionMNIST(
        root="./data", train=False, download=True, transform=transform
    )

    class_names = train_data.classes
    print(class_names)
    print(train_data)
    print(train_data.data.size())

    batch_size = 128

    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)

    dataiter = iter(train_loader)
    images, labels = next(dataiter)
    plt.figure(figsize=(4, 4))
    plt.axis("off")
    plt.title("Training Images")
    inverted_images = t_F.invert(images[0:48])
    plt.imshow(
        np.transpose(
            make_grid(inverted_images.to(device), padding=2, normalize=True).cpu(),
            (1, 2, 0),
        )
    )

    print("Shape of loading one batch:", images.shape)
    print("Total no. of batches present in trainloader:", len(train_loader))

    G = Generator().to(device)
    D = Discriminator().to(device)
    fashion_dim = train_data.data.size(1) * train_data.data.size(2)
    z_dim = 100
    print(fashion_dim)

    # loss
    criterion = nn.BCELoss()

    # optimizer
    lr = 0.0002
    G_optimizer = optim.Adam(G.parameters(), lr=lr)
    D_optimizer = optim.Adam(D.parameters(), lr=lr)

    def G_train(x):
        # =======================Train the generator=======================#
        G.zero_grad()

        z = Variable(torch.randn(batch_size, z_dim).to(device))
        y = Variable(torch.ones(batch_size, 1).to(device))

        G_output = G(z)
        D_output = D(G_output)
        G_loss = criterion(D_output, y)

        # gradient backprop & optimize ONLY G's parameters
        G_loss.backward()
        G_optimizer.step()

        return G_loss.data.item()

    def D_train(x):
        # =======================Train the discriminator=======================#
        D.zero_grad()

        # train discriminator on real
        x_real, y_real = x.view(-1, fashion_dim).to(device), torch.ones(
            x.size(0), 1
        ).to(device)
        x_real, y_real = Variable(x_real), Variable(y_real)

        D_output = D(x_real)
        D_real_loss = criterion(D_output, y_real)
        D_real_score = D_output

        # train discriminator on fake
        z = Variable(torch.randn(x.size(0), z_dim).to(device))
        x_fake, y_fake = G(z), Variable(torch.zeros(x.size(0), 1).to(device))

        D_output = D(x_fake)
        D_fake_loss = criterion(D_output, y_fake)
        D_fake_score = D_output

        # gradient backprop & optimize ONLY D's parameters
        D_loss = D_real_loss + D_fake_loss
        D_loss.backward()
        D_optimizer.step()

        return D_loss.data.item()

    import os

    os.makedirs("samples", exist_ok=True)

    # Function to plot losses
    def plot_losses(d_losses, g_losses):
        plt.figure(figsize=(10, 5))
        plt.plot(d_losses, label="Discriminative loss")
        plt.plot(g_losses, label="Generative loss")
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.legend()
        plt.suptitle("Loss over Epochs")
        plt.savefig("samples/losses.png")

    def plot_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1)):
        noise = torch.randn(examples, z_dim, device=device)
        generated_images = G(noise)
        generated_images = generated_images.reshape(examples, 28, 28)

        plt.figure(figsize=figsize)
        for i in range(examples):
            plt.subplot(dim[0], dim[1], i + 1)
            plt.imshow(
                generated_images[i].cpu().detach().numpy(),
                interpolation="nearest",
                cmap="gray_r",
            )
            plt.axis("off")
        plt.tight_layout()
        plt.savefig("samples/epoch_{:03d}.png".format(epoch))

    n_epoch = 200
    sample_interval = 10
    D_losses, G_losses = [], []
    for epoch in range(1, n_epoch + 1):
        D_loss_epoch = 0.0
        G_loss_epoch = 0.0
        for batch_idx, (x, _) in enumerate(train_loader):
            D_loss_epoch += D_train(x)
            G_loss_epoch += G_train(x)
        D_loss_epoch /= batch_idx + 1
        G_loss_epoch /= batch_idx + 1
        D_losses.append(D_loss_epoch)
        G_losses.append(G_loss_epoch)

        print(
            "[%d/%d]: loss_d: %.3f, loss_g: %.3f"
            % (
                (epoch),
                n_epoch,
                torch.mean(torch.FloatTensor(D_losses)),
                torch.mean(torch.FloatTensor(G_losses)),
            )
        )
        if epoch % sample_interval == 0 or epoch == n_epoch:
            plot_images(epoch, G)

    plot_losses(D_losses, G_losses)

    # save models:
    torch.save(G.state_dict(), "G.pth")
    torch.save(D.state_dict(), "D.pth")

    # Load models:
    G.load_state_dict(torch.load("G.pth"))
    D.load_state_dict(torch.load("D.pth"))

    plt.show()

    classifier = Classifier()
    classifier.train(test_loader)  # Entrenar con datos de test
    classifier.save_model("Classifier.pth")

    num_samples = 5
    noise = torch.randn(num_samples, z_dim).to(device)
    fake_images = G(noise).detach().cpu()

    fake_images = fake_images.view(-1, 1, 28, 28)
    generated_dataset = GeneratedDataset(fake_images)
    generated_loader = DataLoader(generated_dataset, batch_size=128, shuffle=False)

    # load model Classifier
    classifier = Classifier()
    classifier.load_model("Classifier.pth")
    classifier.class_names = class_names
    classifier.predict(generated_loader)
